{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/talpt/pyton/blob/main/7x_Filter_Pivot_%2B_Ichimoku.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfWmktU4Ra1h",
        "outputId": "3dc014a2-c622-4c9d-8166-a38c682394de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/rongardF/tvdatafeed\n",
            "  Cloning https://github.com/rongardF/tvdatafeed to /tmp/pip-req-build-y02hifq0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/rongardF/tvdatafeed /tmp/pip-req-build-y02hifq0\n",
            "  Resolved https://github.com/rongardF/tvdatafeed to commit e6f6aaa7de439ac6e454d9b26d2760ded8dc4923\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tvdatafeed==2.1.0) (75.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from tvdatafeed==2.1.0) (2.2.2)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from tvdatafeed==2.1.0) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from tvdatafeed==2.1.0) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->tvdatafeed==2.1.0) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->tvdatafeed==2.1.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->tvdatafeed==2.1.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->tvdatafeed==2.1.0) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->tvdatafeed==2.1.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->tvdatafeed==2.1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->tvdatafeed==2.1.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->tvdatafeed==2.1.0) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->tvdatafeed==2.1.0) (1.17.0)\n",
            "Building wheels for collected packages: tvdatafeed\n",
            "  Building wheel for tvdatafeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tvdatafeed: filename=tvdatafeed-2.1.0-py3-none-any.whl size=17533 sha256=7871fbe070c9627fc019a19e47b5a5093820a3f203b4eb86500c482d58c8e678\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ecot4x6m/wheels/0a/ba/99/b27476fd1e4caf0dd70445cdc6798195d3b90005a1501a12f7\n",
            "Successfully built tvdatafeed\n",
            "Installing collected packages: tvdatafeed\n",
            "Successfully installed tvdatafeed-2.1.0\n",
            "Collecting tradingview-screener==2.5.0\n",
            "  Downloading tradingview_screener-2.5.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from tradingview-screener==2.5.0) (2.2.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from tradingview-screener==2.5.0) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.2->tradingview-screener==2.5.0) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.2->tradingview-screener==2.5.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.2->tradingview-screener==2.5.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=2.1.2->tradingview-screener==2.5.0) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->tradingview-screener==2.5.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->tradingview-screener==2.5.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->tradingview-screener==2.5.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->tradingview-screener==2.5.0) (2024.12.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.2->tradingview-screener==2.5.0) (1.17.0)\n",
            "Downloading tradingview_screener-2.5.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tradingview-screener\n",
            "Successfully installed tradingview-screener-2.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tvDatafeed.main:you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AKBNK: Long Sinyal\n",
            "AKCNS: Long Sinyal\n",
            "BERA: Long Sinyal\n",
            "BRKVY: Long Sinyal\n",
            "DCTTR: Long Sinyal\n",
            "DGATE: Long Sinyal\n",
            "DYOBY: Long Sinyal\n",
            "EGGUB: Long Sinyal\n",
            "EMKEL: Long Sinyal\n",
            "GIPTA: Long Sinyal\n",
            "GLDTR: Long Sinyal\n",
            "HALKB: Long Sinyal\n",
            "HKTM: Long Sinyal\n",
            "ISCTR: Long Sinyal\n",
            "KNFRT: Long Sinyal\n",
            "MGROS: Long Sinyal\n",
            "NATEN: Long Sinyal\n",
            "OZSUB: Long Sinyal\n",
            "PEHOL: Long Sinyal\n",
            "RALYH: Long Sinyal\n",
            "RAYSG: Long Sinyal\n",
            "SMART: Long Sinyal\n",
            "TCELL: Long Sinyal\n",
            "TSKB: Long Sinyal\n",
            "VAKBN: Long Sinyal\n",
            "YAPRK: Long Sinyal\n",
            "YKBNK: Long Sinyal\n",
            "ZPLIB: Long Sinyal\n",
            "\n",
            "Koşulları sağlayan hisseler:\n",
            "   Hisse Adı  Son Fiyat Sinyal\n",
            "0      AKBNK      68.55   Long\n",
            "1      AKCNS     188.00   Long\n",
            "2       BERA      16.82   Long\n",
            "3      BRKVY      72.75   Long\n",
            "4      DCTTR      36.00   Long\n",
            "5      DGATE      49.98   Long\n",
            "6      DYOBY      30.32   Long\n",
            "7      EGGUB      81.40   Long\n",
            "8      EMKEL      16.73   Long\n",
            "9      GIPTA      46.06   Long\n",
            "10     GLDTR     267.50   Long\n",
            "11     HALKB      18.85   Long\n",
            "12      HKTM      19.19   Long\n",
            "13     ISCTR      14.62   Long\n",
            "14     KNFRT      13.72   Long\n",
            "15     MGROS     554.00   Long\n",
            "16     NATEN      81.00   Long\n",
            "17     OZSUB      35.06   Long\n",
            "18     PEHOL       5.43   Long\n",
            "19     RALYH     342.75   Long\n",
            "20     RAYSG     697.50   Long\n",
            "21     SMART      30.96   Long\n",
            "22     TCELL     102.00   Long\n",
            "23      TSKB      13.59   Long\n",
            "24     VAKBN      26.42   Long\n",
            "25     YAPRK     888.00   Long\n",
            "26     YKBNK      32.58   Long\n",
            "27     ZPLIB     176.75   Long\n"
          ]
        }
      ],
      "source": [
        "# Gerekli kütüphaneleri yükleyin\n",
        "!pip install git+https://github.com/rongardF/tvdatafeed\n",
        "!pip install tradingview-screener==2.5.0\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "from tradingview_screener import get_all_symbols\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "# TvDatafeed nesnesi oluşturma\n",
        "tv = TvDatafeed()\n",
        "\n",
        "# Türkiye piyasasındaki tüm sembolleri almak için\n",
        "try:\n",
        "    Hisseler = get_all_symbols(market='turkey')\n",
        "    Hisseler = [symbol.replace('BIST:', '') for symbol in Hisseler]\n",
        "    Hisseler = sorted(Hisseler)\n",
        "except Exception as e:\n",
        "    print(f\"Hata alındı: {e}\")\n",
        "\n",
        "def _pr(src, length):\n",
        "    highest_high = src.rolling(window=length).max()\n",
        "    lowest_low = src.rolling(window=length).min()\n",
        "    wpr = 100 * (src - highest_high) / (highest_high - lowest_low)\n",
        "    return wpr\n",
        "\n",
        "def variant(type, src, length):\n",
        "    if type == \"SMA\":\n",
        "        return src.rolling(window=length).mean()\n",
        "    elif type == \"EMA\":\n",
        "        return src.ewm(span=length, adjust=False).mean()\n",
        "    elif type == \"WMA\":\n",
        "        weights = np.arange(1, length + 1)\n",
        "        return src.rolling(window=length).apply(lambda prices: np.dot(prices, weights) / weights.sum(), raw=True)\n",
        "    elif type == \"RMA\":\n",
        "        return src.ewm(alpha=1/length, adjust=False).mean()\n",
        "    return src\n",
        "\n",
        "def bollinger_bands(type, src, length, mult):\n",
        "    basis = variant(type, src, length)\n",
        "    dev = mult * src.rolling(window=length).std()\n",
        "    upper = basis + dev\n",
        "    lower = basis - dev\n",
        "    return basis, upper, lower\n",
        "\n",
        "def calculate_momentum(data, window=14):\n",
        "    return data.diff(window)\n",
        "\n",
        "def ichimoku(data):\n",
        "    data['tenkan_sen'] = (data['high'].rolling(window=9).max() + data['low'].rolling(window=9).min()) / 2\n",
        "    data['kijun_sen'] = (data['high'].rolling(window=26).max() + data['low'].rolling(window=26).min()) / 2\n",
        "    data['senkou_span_a'] = ((data['tenkan_sen'] + data['kijun_sen']) / 2).shift(26)\n",
        "    data['senkou_span_b'] = ((data['high'].rolling(window=52).max() + data['low'].rolling(window=52).min()) / 2).shift(26)\n",
        "    data['chikou_span'] = data['close'].shift(-26)\n",
        "\n",
        "def parabolic_sar(data, acceleration=0.02, max_acceleration=0.2):\n",
        "    sar = np.zeros(len(data))\n",
        "    sar[0] = data['close'][0]\n",
        "    is_uptrend = True\n",
        "    ep = data['low'][0]\n",
        "    af = acceleration\n",
        "\n",
        "    for i in range(1, len(data)):\n",
        "        sar[i] = sar[i - 1] + af * (ep - sar[i - 1])\n",
        "        if is_uptrend:\n",
        "            sar[i] = max(sar[i], data['low'][i - 1])\n",
        "            if data['high'][i] > ep:\n",
        "                ep = data['high'][i]\n",
        "                af = min(af + acceleration, max_acceleration)\n",
        "            if data['low'][i] < sar[i]:\n",
        "                is_uptrend = False\n",
        "                sar[i] = ep\n",
        "                ep = data['low'][i]\n",
        "                af = acceleration\n",
        "        else:\n",
        "            sar[i] = min(sar[i], data['high'][i - 1])\n",
        "            if data['low'][i] < ep:\n",
        "                ep = data['low'][i]\n",
        "                af = min(af + acceleration, max_acceleration)\n",
        "            if data['high'][i] > sar[i]:\n",
        "                is_uptrend = True\n",
        "                sar[i] = ep\n",
        "                ep = data['high'][i]\n",
        "                af = acceleration\n",
        "    data['psar'] = sar\n",
        "\n",
        "def calculate_pivot_points(data):\n",
        "    data['pivot'] = (data['high'] + data['low'] + data['close']) / 3\n",
        "    data['support1'] = (2 * data['pivot']) - data['high']\n",
        "    data['resistance1'] = (2 * data['pivot']) - data['low']\n",
        "    data['support2'] = data['pivot'] - (data['high'] - data['low'])\n",
        "    data['resistance2'] = data['pivot'] + (data['high'] - data['low'])\n",
        "\n",
        "def scan_stocks(symbols, interval='1d', n_bars=500, wpr_period=25, wpr_smoothing_period=3, wpr_smoothing_type=\"SMA\", bb_period=89, bb_mult=1.0, bb_type=\"SMA\", wma_length=50, momentum_window=14):\n",
        "    results = []\n",
        "\n",
        "    for symbol in symbols:\n",
        "        try:\n",
        "            # TradingView'dan veri çekme\n",
        "            data = tv.get_hist(symbol=symbol, exchange='BIST', interval=Interval.in_daily, n_bars=n_bars)\n",
        "            if data is None or data.empty:\n",
        "                print(f\"{symbol} için veri bulunamadı veya boş.\")\n",
        "                continue\n",
        "\n",
        "            # Williams %R hesaplama\n",
        "            data['wpr'] = (_pr(data['close'], wpr_period) + 50.0) * 2.0\n",
        "            data['wpr_smoothed'] = variant(wpr_smoothing_type, data['wpr'], wpr_smoothing_period)\n",
        "\n",
        "            # Bollinger Bands hesaplama\n",
        "            middle, upper, lower = bollinger_bands(bb_type, data['wpr_smoothed'], bb_period, bb_mult)\n",
        "            data['bb_middle'] = middle\n",
        "            data['bb_upper'] = upper\n",
        "            data['bb_lower'] = lower\n",
        "\n",
        "            # WMA hesaplama\n",
        "            data['wma'] = variant(\"WMA\", data['close'], wma_length)\n",
        "\n",
        "            # Momentum hesaplama\n",
        "            data['momentum'] = calculate_momentum(data['close'], window=momentum_window)\n",
        "\n",
        "            # Ichimoku ve Parabolic SAR hesaplama\n",
        "            ichimoku(data)\n",
        "            parabolic_sar(data)\n",
        "\n",
        "            # Pivot noktaları hesaplama\n",
        "            calculate_pivot_points(data)\n",
        "\n",
        "            # Koşulları kontrol etme\n",
        "            data['go_long'] = (\n",
        "                (data['wpr_smoothed'] > data['bb_upper']) &\n",
        "                (data['close'] > data['wma']) &\n",
        "                (data['momentum'] > 0) &\n",
        "                (data['close'] > data['psar']) &\n",
        "                (data['tenkan_sen'] > data['kijun_sen']) &\n",
        "                (data['close'] > data['senkou_span_a']) &\n",
        "                (data['close'] > data['senkou_span_b']) &\n",
        "                (data['close'] > data['pivot']) # Fiyat pivotu yukarı kestiği durumda\n",
        "            )\n",
        "            is_long = data.iloc[-1]['go_long']\n",
        "\n",
        "            # Debugging: Koşul sonuçlarını yazdırma\n",
        "            if is_long:\n",
        "                print(f\"{symbol}: Long Sinyal\")\n",
        "\n",
        "            # Sadece 'True' sinyalleri sonuç olarak ekleme\n",
        "            if is_long:\n",
        "                results.append({\n",
        "                    'Hisse Adı': symbol,\n",
        "                    'Son Fiyat': data.iloc[-1]['close'],\n",
        "                    'Sinyal': 'Long'\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"Hata alındı {symbol}: {e}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Tarama işlemini başlatma\n",
        "results = scan_stocks(Hisseler, interval='1d', n_bars=500)\n",
        "\n",
        "# Sonuçları gösterme\n",
        "if results:\n",
        "    df_results = pd.DataFrame(results)\n",
        "    print(\"\\nKoşulları sağlayan hisseler:\")\n",
        "    print(df_results)\n",
        "else:\n",
        "    print(\"\\nHiçbir hisse tarama koşulunu sağlamıyor.\")"
      ]
    }
  ]
}